<!DOCTYPE HTML>
<html>
	<head>
		<title>Home Automation</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<meta name="description" content="" />
		<meta name="keywords" content="" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="is-preload">

		<!-- Header -->
			<header id="header">
				<a class="logo" href="index.html">Home Automation</a>
				<nav>
					<a href="#menu">Menu</a>
				</nav>
			</header>

		<!-- Nav -->
			<nav id="menu">
				<ul class="links">
					<li><a href="index.html">Home</a></li>
					<li><a href="login.html">Login</a></li>
					<li><a href="signup.html">Sign Up</a></li>
				</ul>
			</nav>

		<!-- Banner -->
			<section id="banner">
				<div class="inner">
					<h1>Home Automation</h1>
					<p>Control Whatâ€™s In Your Home<br />
				<a href=""></a>In One Click</p>
				</div>
				<video autoplay loop muted playsinline src="images/banner.mp4"></video>
			</section>

		<!-- Highlights -->
			<section class="wrapper">
				<div class="inner">
					<header class="special">
						
						</header>
					<div class="highlights">
						<section>
							
								
								<div class="author">
									
									
								</div>
							
						</section>
						<section>
							
								
								<div class="content">
								<header>
									<a href="websockets-3.htm"><img src="al.png"height="150" width="150"></img></a>
									<h3>CONTROL SWITCH</h3>
								</header>
								<p>switch ON/OFF the home appliances</p>
							</div>
							
						</section>
						<section>
							
								
								<div class="author">
									
									
								</div>
							
						</section>
						<section>
							<div class="content">
								<header>
									<img src="w1.png"height="150" width="150"></img>
									<h3>FIRE SENSOR</h3>
								</header>
								<p>A fire sensor designed to detect and respond to the presence of a flame or fire</p>
							</div>
						</section>
						<section>
							<div class="content">
								<header>
									<img src="w.png"height="150" width="150"></img>
									<h3>TFT DISPLAY</h3>
								</header>
								<p>Thin-film-transistor liquid-crystal display (TFT LCD) </p>
							</div>
						</section>
						<section>
							<div class="content">
								<header>
									<img src="w2.png"height="150" width="150"></img>
									<h3>FINGERPRINT SENSOR</h3>
								</header>
								<p>Fingerprint scanners are security systems of biometrics</p>
							</div>
						</section>
						<section>
							
						</section>
						<section>
							<!-- <div class="content">
								<header>
									<a href="https://autosmartech.000webhostapp.com/m.php"><img src="map.png" height="150" width="150"></img></a>
									<h3>TRACE LOCATION</h3>
								</header>
								<p>traces the current location and projects on google map</p>
							</div> -->
						</section>
						<section>
							
						</section>
					</div>
				</div>
			</section>

		<!-- CTA -->
			<section id="cta" class="wrapper">
				<div class="inner">
					<h2>NODE MCU</h2>
					<p>NodeMCU is an open source IoT platform.It includes firmware which runs on the ESP8266 Wi-Fi SoC from Espressif Systems, 
						and hardware which is based on the ESP-12 module.The term "NodeMCU" by default refers to the firmware rather than 
						the development kits. The firmware uses the Lua scripting language. It is based on the eLua project, and built on 
						the Espressif Non-OS SDK for ESP8266. It uses many open source projects, such as lua-cjson and SPIFFS.</p>
				</div>
			</section>

		<!-- Testimonials -->
			<section class="wrapper">
				<div class="inner">
					<header class="special">
						<h2>INTERFACE</h2>
						<p>The ability to track a person's movements and determine what gestures they may be performing can be achieved through various tools. The kinetic user interfaces (KUIs)are an emerging type of user interfaces that allow users to interact with computing devices through the motion of objects and bodies. Examples of KUIs include tangible user interfacesand motion-aware games such as Wii and Microsoft's Kinect,and other interactive projects.

                        Although there is a large amount of research done in image/video based gesture recognition, there is some variation within the tools and environments used between implementations.</p>
					</header>
					<div class="testimonials">
					      
						
						<section>
							
								
								<div class="author">
									
									
								</div>
							
						</section>
						<section>
							<div class="content">
								<blockquote>
									<p>phone:8870870891 tdv@vcet.ac.in</p>
								</blockquote>
								<div class="author">
									<div class="image">
										<img src="d.jpg" alt="" />
									</div>
									<p class="credit">- <strong>Dr. S. Dhanalakshmi<br>
										Associate Professor</strong> <span>Guide</span></p>
								</div>
							</div>
						</section>					
						<section>
							
								
								<div class="author">
									
									
								</div>
							
						</section>
						<section>
							<div class="content">
								<blockquote>
									<p>phone:9789121679 leorandal1997@gmail.com</p>
								</blockquote>
								<div class="author">
									<div class="image">
										<img src="l.png" alt="" />
									</div>
									<p class="credit">- <strong>V.Leo Randal</strong> <span>hardware</span></p>
								</div>
							</div>
						</section>
						<section>
							<div class="content">
								<blockquote>
									<p>phone:9585660890 hemanthkrishna2798@gmail.com</p>
								</blockquote>
								<div class="author">
									<div class="image">
										<img src="h.png" alt="" />
									</div>
									<p class="credit">- <strong>K.Hemanth</strong> <span>web</span></p>
								</div>
							</div>
						</section>
						<section>
							<div class="content">
								<blockquote>
									<p>phone:9585660890 anandkarthikeyan1998@gmail.com</p>
								</blockquote>
								<div class="author">
									<div class="image">
										<img src="a.png" alt="" />
									</div>
									<p class="credit">- <strong>K.Anand Prabhu</strong> <span>app</span></p>
								</div>
							</div>
						</section>
						
						<section>
							
								
								<div class="author">
									
									
								</div>
							
						</section>
						
						
						<!-- <section>
							<div class="content">
								<blockquote>
									<p>phone:9790595521 murugavenkateshan@gmail.com</p>
								</blockquote>
								<div class="author">
									<div class="image">
										<img src="mvr.JPG" alt="" />
									</div>
									<p class="credit">- <strong>Muruga Venkatesh.R</strong> <span>Hardware</span></p>
								</div>
							</div>
						</section> -->
						
						
						
						<section>
							
								
								<div class="author">
									
									
								</div>
							
						</section>
					</div>
				</div>
			</section>

		<!-- Footer -->
			<footer id="footer">
				<div class="inner">
					<div class="content">
						<section>
							<h3>Gesture recognition</h3>
							<p>Gesture recognition is a topic in computer science and language technology with the goal of interpreting human gestures via mathematical algorithms. Gestures can originate from any bodily motion or state but commonly originate from the face or hand. Current focuses in the field include emotion recognition from face and hand gesture recognition. Users can use simple gestures to control or interact with devices without physically touching them. Many approaches have been made using cameras and computer vision algorithms to interpret sign language. However, the identification and recognition of posture, gait, proxemics, and human behaviors is also the subject of gesture recognition techniques.Gesture recognition can be seen as a way for computers to begin to understand human body language, thus building a richer bridge between machines and humans than primitive text user interfaces or even GUIs (graphical user interfaces), which still limit the majority of input to keyboard and mouse.</p>
						</section>
						
						<section>
							<h4>Social</h4>
							<ul class="plain">
								
								<li><a href="#"><i class="icon fa-facebook">&nbsp;</i>Facebook</a></li>
								
								
							</ul>
						</section>
					</div>
					<div class="copyright">
						&copy; autosmartech 2019
					</div>
				</div>
			</footer>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
